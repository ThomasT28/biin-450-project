data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[1]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[2]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[3]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[4]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[5]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[6]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[7]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
data("BLOSUM62")
alignment <- msaClustalOmega(sequences[[8]]) # Manual
msaPrettyPrint(alignment, output= "pdf", verbose = TRUE) # TEST
rm(list = ls())
library(tidyverse)
library(lubridate)
library(rentrez)
library(Biostrings)
library(msa)
# Backup File Handles: To avoid recomputing
file_handles <- c('hemagglutinin_seqs_2010.fasta', 'hemagglutinin_seqs_2011.fasta', 'hemagglutinin_seqs_2012.fasta', 'hemagglutinin_seqs_2013.fasta', 'hemagglutinin_seqs_2014.fasta', 'hemagglutinin_seqs_2015.fasta', 'hemagglutinin_seqs_2016.fasta', 'hemagglutinin_seqs_2017.fasta')
sequences <- list()
for (path in file_handles){
seq <- readAAStringSet(path)
sequences <- c(sequences, seq)
}
# Load Data > 'NCBI_data.csv'
data <- read_csv("NCBI_data.csv")
# Convert date column to lubridate value.
data$collection_date <- as_date(data$collection_date)
# Add new column containing dates rounded to desired Time Block (Nearest Year)
data <- data %>%
mutate(year = format(data$collection_date, "%Y"))
# Split data into sub-tables and then download sequences for proteins within the Time Blocks
block_list <- data %>%
group_by(year) %>%
group_split()
# An MSA can not be performed if less than 3 seqs are present
# There is enough data, but this is still an important to avoid an error
seq_counts <- list()
for (block in block_list){
count <- nrow(block)
seq_counts <- c(seq_counts, count)
}
rm(list = ls())
library(tidyverse)
library(lubridate)
library(rentrez)
library(Biostrings)
library(msa)
# USE: Takes Block List, downloads sequences into individual text files.
# INPUT: Vector of data sub-tables grouped by time
# OUTPUT: Creates .txt files containing sequences for each time block, returns list of file names
download_sequences <- function(time_blocks){
file_names <- list()
for (block in time_blocks){
accession_nums <- pull(block, accession)
file_name <- paste(
as.character(block[1, "protein"]),
'_seqs_',
as.character(block[1, "year"]),
'.fasta',
sep='')
file.create(file_name)
file_names <- c(file_names, file_name)
for (num in accession_nums){
sequence <- entrez_fetch(db="protein", id=num, rettype="fasta")
write(sequence, file_name,append=TRUE)
}
} # Time Block Loop - Closing Bracket
return(file_names)
} # Function Closing Bracket
# USE: Computes all conservation scores from MSAs derived from time blocks
# INPUT: AAseqs from protein sequence files, count of sequences in each file and the time block list.
# OUTPUT: Generates raw conservation score data file and a Chimera attribute file for each time block. Returns file names.
compute_conservation <- function(seqs, counts, blocks){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'raw_consensus_scores',
'.fasta',
sep='')
file.create(file_name)
years <- c()
for (block in blocks){
years <- c(years, as.character(block[1,"year"]))
}
file_handles <- c(file_name)
index <- 1
for (seq in seqs){
if (counts[[index]] >= 3){
alignment <- msaClustalOmega(seq)
scores <- msaConservationScore(alignment, BLOSUM62)
write(paste('>Year: ', years[[index]], sep = ""), file_name, append = TRUE)
write(scores, file_name, append = TRUE)
chimera_file_name <- generate_chimera_attribute_files(seq, blocks[[index]], scores) #novel
file_handles <- c(file_handles, chimera_file_name)
}
index <- index + 1
}
return(file_handles)
} # Function End Bracket
# USE: Helper function for compute_conservation(), generates Chimera attribute files
# INPUT: One MSA sequences object, its matching time block and the computed scores
# INPUT: Generates Attribute file and returns its name
generate_chimera_attribute_files <- function(seq, block, scores){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'_consensus_chimera_',
as.character(block[1, "year"]),
'.txt',
sep='')
file.create(file_name)
write(c(paste('attribute: conservation', as.character(block[1, "year"]), sep = '_'),
'match mode: any', 'recipient: residues'),
file_name, append = TRUE)
index <- 1
for (conNum in scores){
write(paste('\t:', as.character(index), '\t', as.character(conNum), sep = ''), file_name, append = TRUE)
index <- index + 1
}
return(file_name)
} # Function End Bracket
# Load Data > 'NCBI_data.csv'
#data <- read_csv("NCBI_data.csv")
data <-read_csv("NCBI_NA_data.csv")
# Convert date column to lubridate value.
data$collection_date <- as_date(data$collection_date)
# Add new column containing dates rounded to desired Time Block (Nearest Year)
data <- data %>%
mutate(year = format(data$collection_date, "%Y"))
# Split data into sub-tables and then download sequences for proteins within the Time Blocks
block_list <- data %>%
group_by(year) %>%
group_split()
# SET API KEY
set_entrez_key("4460fcbbf1baa92f669e7affbdb9ef6a0d0a") #README: Insert NCBI generated Entrez key
Sys.getenv("ENTREZ_KEY")
# Write Seqs to file
file_handles <- download_sequences(block_list)
# An MSA can not be performed if less than 3 seqs are present
# There is enough data, but this is still an important to avoid an error
seq_counts <- list()
for (block in block_list){
count <- nrow(block)
seq_counts <- c(seq_counts, count)
}
# Backup File Handles: To avoid recomputing
file_handles <- c('hemagglutinin_seqs_2010.fasta', 'hemagglutinin_seqs_2011.fasta', 'hemagglutinin_seqs_2012.fasta', 'hemagglutinin_seqs_2013.fasta', 'hemagglutinin_seqs_2014.fasta', 'hemagglutinin_seqs_2015.fasta', 'hemagglutinin_seqs_2016.fasta', 'hemagglutinin_seqs_2017.fasta')
sequences <- list()
for (path in file_handles){
seq <- readAAStringSet(path)
sequences <- c(sequences, seq)
}
library(tidyverse)
library(lubridate)
library(rentrez)
library(Biostrings)
library(msa)
# USE: Takes Block List, downloads sequences into individual text files.
# INPUT: Vector of data sub-tables grouped by time
# OUTPUT: Creates .txt files containing sequences for each time block, returns list of file names
download_sequences <- function(time_blocks){
file_names <- list()
for (block in time_blocks){
accession_nums <- pull(block, accession)
file_name <- paste(
as.character(block[1, "protein"]),
'_seqs_',
as.character(block[1, "year"]),
'.fasta',
sep='')
file.create(file_name)
file_names <- c(file_names, file_name)
for (num in accession_nums){
sequence <- entrez_fetch(db="protein", id=num, rettype="fasta")
write(sequence, file_name,append=TRUE)
}
} # Time Block Loop - Closing Bracket
return(file_names)
} # Function Closing Bracket
# USE: Computes all conservation scores from MSAs derived from time blocks
# INPUT: AAseqs from protein sequence files, count of sequences in each file and the time block list.
# OUTPUT: Generates raw conservation score data file and a Chimera attribute file for each time block. Returns file names.
compute_conservation <- function(seqs, counts, blocks){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'raw_consensus_scores',
'.fasta',
sep='')
file.create(file_name)
years <- c()
for (block in blocks){
years <- c(years, as.character(block[1,"year"]))
}
file_handles <- c(file_name)
index <- 1
for (seq in seqs){
if (counts[[index]] >= 3){
alignment <- msaClustalOmega(seq)
scores <- msaConservationScore(alignment, BLOSUM62)
write(paste('>Year: ', years[[index]], sep = ""), file_name, append = TRUE)
write(scores, file_name, append = TRUE)
chimera_file_name <- generate_chimera_attribute_files(seq, blocks[[index]], scores) #novel
file_handles <- c(file_handles, chimera_file_name)
}
index <- index + 1
}
return(file_handles)
} # Function End Bracket
# USE: Helper function for compute_conservation(), generates Chimera attribute files
# INPUT: One MSA sequences object, its matching time block and the computed scores
# INPUT: Generates Attribute file and returns its name
generate_chimera_attribute_files <- function(seq, block, scores){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'_consensus_chimera_',
as.character(block[1, "year"]),
'.txt',
sep='')
file.create(file_name)
write(c(paste('attribute: conservation', as.character(block[1, "year"]), sep = '_'),
'match mode: any', 'recipient: residues'),
file_name, append = TRUE)
index <- 1
for (conNum in scores){
write(paste('\t:', as.character(index), '\t', as.character(conNum), sep = ''), file_name, append = TRUE)
index <- index + 1
}
return(file_name)
} # Function End Bracket
# Load Data > 'NCBI_data.csv'
#data <- read_csv("NCBI_data.csv")
data <-read_csv("NCBI_NA_data.csv")
# Convert date column to lubridate value.
data$collection_date <- as_date(data$collection_date)
# Add new column containing dates rounded to desired Time Block (Nearest Year)
data <- data %>%
mutate(year = format(data$collection_date, "%Y"))
# Split data into sub-tables and then download sequences for proteins within the Time Blocks
block_list <- data %>%
group_by(year) %>%
group_split()
# SET API KEY
set_entrez_key("4460fcbbf1baa92f669e7affbdb9ef6a0d0a") #README: Insert NCBI generated Entrez key
Sys.getenv("ENTREZ_KEY")
# Write Seqs to file
file_handles <- download_sequences(block_list)
library(tidyverse)
library(lubridate)
library(rentrez)
library(Biostrings)
library(msa)
# USE: Takes Block List, downloads sequences into individual text files.
# INPUT: Vector of data sub-tables grouped by time
# OUTPUT: Creates .txt files containing sequences for each time block, returns list of file names
download_sequences <- function(time_blocks){
file_names <- list()
for (block in time_blocks){
accession_nums <- pull(block, accession)
file_name <- paste(
as.character(block[1, "protein"]),
'_seqs_',
as.character(block[1, "year"]),
'.fasta',
sep='')
file.create(file_name)
file_names <- c(file_names, file_name)
for (num in accession_nums){
sequence <- entrez_fetch(db="protein", id=num, rettype="fasta")
write(sequence, file_name,append=TRUE)
}
} # Time Block Loop - Closing Bracket
return(file_names)
} # Function Closing Bracket
# USE: Computes all conservation scores from MSAs derived from time blocks
# INPUT: AAseqs from protein sequence files, count of sequences in each file and the time block list.
# OUTPUT: Generates raw conservation score data file and a Chimera attribute file for each time block. Returns file names.
compute_conservation <- function(seqs, counts, blocks){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'raw_consensus_scores',
'.fasta',
sep='')
file.create(file_name)
years <- c()
for (block in blocks){
years <- c(years, as.character(block[1,"year"]))
}
file_handles <- c(file_name)
index <- 1
for (seq in seqs){
if (counts[[index]] >= 3){
alignment <- msaClustalOmega(seq)
scores <- msaConservationScore(alignment, BLOSUM62)
write(paste('>Year: ', years[[index]], sep = ""), file_name, append = TRUE)
write(scores, file_name, append = TRUE)
chimera_file_name <- generate_chimera_attribute_files(seq, blocks[[index]], scores) #novel
file_handles <- c(file_handles, chimera_file_name)
}
index <- index + 1
}
return(file_handles)
} # Function End Bracket
# USE: Helper function for compute_conservation(), generates Chimera attribute files
# INPUT: One MSA sequences object, its matching time block and the computed scores
# INPUT: Generates Attribute file and returns its name
generate_chimera_attribute_files <- function(seq, block, scores){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'_consensus_chimera_',
as.character(block[1, "year"]),
'.txt',
sep='')
file.create(file_name)
write(c(paste('attribute: conservation', as.character(block[1, "year"]), sep = '_'),
'match mode: any', 'recipient: residues'),
file_name, append = TRUE)
index <- 1
for (conNum in scores){
write(paste('\t:', as.character(index), '\t', as.character(conNum), sep = ''), file_name, append = TRUE)
index <- index + 1
}
return(file_name)
} # Function End Bracket
# Load Data > 'NCBI_data.csv'
#data <- read_csv("NCBI_data.csv")
data <-read_csv("NCBI_NA_data.csv")
# Convert date column to lubridate value.
data$collection_date <- as_date(data$collection_date)
# Add new column containing dates rounded to desired Time Block (Nearest Year)
data <- data %>%
mutate(year = format(data$collection_date, "%Y"))
# Split data into sub-tables and then download sequences for proteins within the Time Blocks
block_list <- data %>%
group_by(year) %>%
group_split()
# SET API KEY
set_entrez_key("4460fcbbf1baa92f669e7affbdb9ef6a0d0a") #README: Insert NCBI generated Entrez key
Sys.getenv("ENTREZ_KEY")
# Write Seqs to file
file_handles <- download_sequences(block_list)
# An MSA can not be performed if less than 3 seqs are present
# There is enough data, but this is still an important to avoid an error
seq_counts <- list()
for (block in block_list){
count <- nrow(block)
seq_counts <- c(seq_counts, count)
}
# Backup File Handles: To avoid recomputing
file_handles <- c('hemagglutinin_seqs_2010.fasta', 'hemagglutinin_seqs_2011.fasta', 'hemagglutinin_seqs_2012.fasta', 'hemagglutinin_seqs_2013.fasta', 'hemagglutinin_seqs_2014.fasta', 'hemagglutinin_seqs_2015.fasta', 'hemagglutinin_seqs_2016.fasta', 'hemagglutinin_seqs_2017.fasta')
sequences <- list()
for (path in file_handles){
seq <- readAAStringSet(path)
sequences <- c(sequences, seq)
}
library(tidyverse)
library(lubridate)
library(rentrez)
library(Biostrings)
library(msa)
# USE: Takes Block List, downloads sequences into individual text files.
# INPUT: Vector of data sub-tables grouped by time
# OUTPUT: Creates .txt files containing sequences for each time block, returns list of file names
download_sequences <- function(time_blocks){
file_names <- list()
for (block in time_blocks){
accession_nums <- pull(block, accession)
file_name <- paste(
as.character(block[1, "protein"]),
'_seqs_',
as.character(block[1, "year"]),
'.fasta',
sep='')
file.create(file_name)
file_names <- c(file_names, file_name)
for (num in accession_nums){
sequence <- entrez_fetch(db="protein", id=num, rettype="fasta")
write(sequence, file_name,append=TRUE)
}
} # Time Block Loop - Closing Bracket
return(file_names)
} # Function Closing Bracket
# USE: Computes all conservation scores from MSAs derived from time blocks
# INPUT: AAseqs from protein sequence files, count of sequences in each file and the time block list.
# OUTPUT: Generates raw conservation score data file and a Chimera attribute file for each time block. Returns file names.
compute_conservation <- function(seqs, counts, blocks){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'raw_consensus_scores',
'.fasta',
sep='')
file.create(file_name)
years <- c()
for (block in blocks){
years <- c(years, as.character(block[1,"year"]))
}
file_handles <- c(file_name)
index <- 1
for (seq in seqs){
if (counts[[index]] >= 3){
alignment <- msaClustalOmega(seq)
scores <- msaConservationScore(alignment, BLOSUM62)
write(paste('>Year: ', years[[index]], sep = ""), file_name, append = TRUE)
write(scores, file_name, append = TRUE)
chimera_file_name <- generate_chimera_attribute_files(seq, blocks[[index]], scores) #novel
file_handles <- c(file_handles, chimera_file_name)
}
index <- index + 1
}
return(file_handles)
} # Function End Bracket
# USE: Helper function for compute_conservation(), generates Chimera attribute files
# INPUT: One MSA sequences object, its matching time block and the computed scores
# INPUT: Generates Attribute file and returns its name
generate_chimera_attribute_files <- function(seq, block, scores){
data("BLOSUM62")
file_name <- paste(
as.character(block[1, "protein"]),
'_consensus_chimera_',
as.character(block[1, "year"]),
'.txt',
sep='')
file.create(file_name)
write(c(paste('attribute: conservation', as.character(block[1, "year"]), sep = '_'),
'match mode: any', 'recipient: residues'),
file_name, append = TRUE)
index <- 1
for (conNum in scores){
write(paste('\t:', as.character(index), '\t', as.character(conNum), sep = ''), file_name, append = TRUE)
index <- index + 1
}
return(file_name)
} # Function End Bracket
# Load Data > 'NCBI_data.csv'
#data <- read_csv("NCBI_data.csv")
data <-read_csv("NCBI_NA_data.csv")
# Convert date column to lubridate value.
data$collection_date <- as_date(data$collection_date)
# Add new column containing dates rounded to desired Time Block (Nearest Year)
data <- data %>%
mutate(year = format(data$collection_date, "%Y"))
# Split data into sub-tables and then download sequences for proteins within the Time Blocks
block_list <- data %>%
group_by(year) %>%
group_split()
# SET API KEY
set_entrez_key("4460fcbbf1baa92f669e7affbdb9ef6a0d0a") #README: Insert NCBI generated Entrez key
Sys.getenv("ENTREZ_KEY")
# Write Seqs to file
file_handles <- download_sequences(block_list)
# An MSA can not be performed if less than 3 seqs are present
# There is enough data, but this is still an important to avoid an error
seq_counts <- list()
for (block in block_list){
count <- nrow(block)
seq_counts <- c(seq_counts, count)
}
sequences <- list()
for (path in file_handles){
seq <- readAAStringSet(path)
sequences <- c(sequences, seq)
}
con_score_handles <- compute_conservation(sequences, seq_counts, block_list)
# Create a Chimera Script which cycles through conservation scores
con_atr_files <- con_score_handles[-1] # Paths of Chimera compt. attribute files
cmd_name <- 'chimera_cmd_script.txt'
pdb_code <- '4M4Y'
del_chains <- c('b', 'd', 'f') # Chains to DELETE from final structure, make this vector empty if no deletions
file.create(cmd_name)
write('# README: Move cmd and attribute files to Chimera directory or Set with - cd [directory_path]', cmd_name, append = TRUE)
write('# WARNING: May generate lag > Run Script with - read [cmd_file_path] ')
write(c('close all; wait 10', paste('open ', pdb_code, '; wait 10', sep=''), 'del ligand; wait 10', 'del solvent; wait 10', 'background solid black; wait 10', 'scale 0.7; wait 10'), cmd_name, append = TRUE)
write('turn x 50', cmd_name, append = TRUE)
if (length(del_chains) > 0 ){
for (chain in del_chains){
write(paste('del :.', chain, ';', sep = ''), cmd_name, append = TRUE)
}
}
for (path in con_atr_files){
year <- str_split(path, '_')
year <- unlist(year)
year <- year[4]
year <- substr(year, 1, 4)
write(paste('defattr ', as.character(path), ' raiseTool false; sleep 2', sep =''), cmd_name, append = TRUE)
write(paste('rangecolor ', 'conservation_', as.character(year), ' min cyan mid red', sep = ''), cmd_name, append = TRUE)
write(paste('copy file ', as.character(year), '_SideView_', pdb_code, '.png png', sep = ''), cmd_name, append = TRUE)
write('turn x 100', cmd_name, append = TRUE)
write(paste('copy file ', as.character(year), '_TopDown_', pdb_code, '.png png', sep = ''), cmd_name, append = TRUE)
write('turn x -100', cmd_name, append = TRUE)
write('sleep 120', cmd_name, append = TRUE)
}
write(paste('write 0 ', pdb_code, '_HITTS.pdb', sep=''), cmd_name, append = TRUE)
print(paste('ANALYSIS GENERATED: See README in ', as.character(cmd_name)))
rm(list = ls())
